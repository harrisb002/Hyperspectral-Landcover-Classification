{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7nS3fagRSAH"
      },
      "source": [
        "- **Orginally created by: Samuel Hobbs on 12/8/2024**\n",
        "- **Last edited by: Ben Harris 1/9/2024**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhjuQxnD3Pki"
      },
      "source": [
        "## The scriptâ€™s primary goal is to:\n",
        "\n",
        "- Read hyperspectral .tiff files from designated directories.\n",
        "\n",
        "- Check that each .tiff file matches a valid resolution range (e.g., 4.0 - 7.0 currently).\n",
        "\n",
        "- Verify that each .tiff file has a label in a corresponding CSV (via sample number).\n",
        "\n",
        "- Convert each .tiff file into a pandas DataFrame where each row represents one pixel, and columns represent the spectral bands plus additional metadata (e.g., filename, label, resolution shape).\n",
        "\n",
        "- Concatenate all the individual DataFrames into a single large DataFrame of pixel-level data for all valid .tiff files.\n",
        "\n",
        "- Save the resulting DataFrame (and an accompanying file-UID map) as a CSV file.\n",
        "\n",
        "- Once that main CSV is saved we add pixel-level coordinates within each image used for displaying results as well as post-processing morphology.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2urNHkRy-5A1"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv-jWjKh-jC3"
      },
      "source": [
        "### Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvJ_X8M8-djY",
        "outputId": "06eac7a9-1b39-4f55-e795-65f7a08e5a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.12.14)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg6txo5K-nxm"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o_iOGIRD80Fd"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join, basename, normpath\n",
        "from google.colab import drive\n",
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5aJk6Q1-9Ep"
      },
      "source": [
        "### Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "lmdr667V_IGI",
        "outputId": "cf03dd2e-512f-40c1-a6a7-87ce661141ce"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLmTehCoOnsp"
      },
      "source": [
        "### File Paths\n",
        "NOTE: Please update these paths as needed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFDLndDWXMdx"
      },
      "outputs": [],
      "source": [
        "#Directories\n",
        "main_dir     = '/content/drive/Shareddrives/Land_Classification_Training_shared/Land_Classification_training_work/'\n",
        "samples_dir  = join(main_dir, 'Samples/')  # Directory where the .tiff files are located as well as the corresponding csv defining their resp. resolutions\n",
        "\n",
        "# Directory containing all .tiff files\n",
        "tiff_dir     = join(samples_dir, 'ANG_L2A_v2_sample_subset')\n",
        "\n",
        "# CSV that contains resolution info (columns: file_name, x_res, y_res)\n",
        "res_csv_path = join(samples_dir, 'ANG_L2A_v2_sample_subset_resolutions.csv')\n",
        "\n",
        "# CSV containing labels for each sample_num\n",
        "labels_csv   = join(main_dir, 'labels.csv')\n",
        "\n",
        "# Output CSV file names and paths\n",
        "csv_dir                 = join(main_dir, 'Updated/')\n",
        "csv_file_name_samples   = 'samples_single_dir.csv'   # main pixel-level data\n",
        "csv_file_name_uid       = 'files_single_dir.csv'     # file-UID map\n",
        "path_to_save_sample_csv = join(csv_dir, csv_file_name_samples)\n",
        "path_to_save_uid_csv    = join(csv_dir, csv_file_name_uid)\n",
        "\n",
        "# These correspond to the columns in the labels CSV that contain (sample_num, label).\n",
        "# If the labels.csv columns differ, update accordingly. (However these are used in later steps in modeling to try to keep consistent!)\n",
        "label_col_sample_num = 'Sample_num'\n",
        "label_col_label      = 'Class'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7n8gu-gWFU0"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzSS_fnpo3UK"
      },
      "source": [
        "### General Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPQnOtUXl_Cl"
      },
      "outputs": [],
      "source": [
        "def get_labels(\n",
        "  file_path,\n",
        "  col1='Sample_num',\n",
        "  col2='Class',\n",
        "  name_col_id='Sample_num',\n",
        "  name_col_label='Label'\n",
        "):\n",
        "  \"\"\"\n",
        "  Reads a CSV of labels from `file_path`. Subsets two columns (col1, col2),\n",
        "  renames them, and sorts by col1 ascending. Returns the resulting DataFrame.\n",
        "\n",
        "  Paramaters:\n",
        "    file_path: Path to the labels CSV.\n",
        "    col1: Name of the column in the CSV that holds the sample number.\n",
        "    col2: Name of the column in the CSV that holds the label/class.\n",
        "    name_col_id: Desired name for the ID column in the returned DataFrame.\n",
        "    name_col_label: Desired name for the label column in the returned DataFrame.\n",
        "\n",
        "  Returns:\n",
        "    A sorted Pandas DataFrame with columns [name_col_id, name_col_label].\n",
        "  \"\"\"\n",
        "  df_labels = (\n",
        "    pd.read_csv(file_path)[[col1, col2]]\n",
        "    .rename(columns={col1: name_col_id, col2: name_col_label})\n",
        "    .sort_values(by=name_col_id, ascending=True)\n",
        "  )\n",
        "  return df_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgKXX7uYmUZn"
      },
      "outputs": [],
      "source": [
        "def trim_data_files(\n",
        "  filenames,\n",
        "  labels,\n",
        "  sample_num_col_name='Sample_num'\n",
        "):\n",
        "  \"\"\"\n",
        "  Trims a list of filenames by matching them to provided labels (by sample_num).\n",
        "  Only retains filenames whose leading integer matches a label's sample number.\n",
        "\n",
        "  Parameters:\n",
        "    filenames: Sorted list or array of filename strings (ex: \"12_abcdef.tiff\").\n",
        "    labels: Pandas DataFrame of labels, sorted by sample_num_col_name.\n",
        "    sample_num_col_name: Column in `labels` that matches the file prefix (sample_num).\n",
        "\n",
        "  Returns:\n",
        "    A numpy array of matching filenames.\n",
        "  \"\"\"\n",
        "  trimmed_filenames = []\n",
        "\n",
        "  size_label      = labels.shape[0]\n",
        "  size_filenames  = len(filenames)\n",
        "\n",
        "  count_label     = 0\n",
        "  count_filenames = 0\n",
        "\n",
        "  while (count_label < size_label and count_filenames < size_filenames):\n",
        "    filename_num = int(filenames[count_filenames].split('_')[0])\n",
        "    label_num    = int(labels[sample_num_col_name].iloc[count_label])\n",
        "\n",
        "    if filename_num == label_num:\n",
        "      trimmed_filenames.append(filenames[count_filenames])\n",
        "      count_filenames += 1\n",
        "    elif filename_num > label_num:\n",
        "      count_label += 1\n",
        "    else:  # filename_num < label_num\n",
        "      count_filenames += 1\n",
        "\n",
        "  # Ensure we have at least some matching samples\n",
        "  assert len(trimmed_filenames) > 0, \"No filenames match the given labels.\"\n",
        "\n",
        "  return np.array(trimmed_filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViTfRoKzPkbz"
      },
      "outputs": [],
      "source": [
        "def check_res(\n",
        "  filename,\n",
        "  res_dict,\n",
        "  min_res_bound=4.0,\n",
        "  max_res_bound=7.0\n",
        "):\n",
        "  \"\"\"\n",
        "  Checks if the x/y resolution of a given filename is within the min/max bound.\n",
        "  Instead of reading resolution from Rasterio, we read from a dictionary\n",
        "  (filename -> (xres, yres)) that was loaded from a CSV file.\n",
        "\n",
        "  Parameters:\n",
        "    filename: The .tiff filename (string).\n",
        "    res_dict: Dictionary with structure {filename: (xres, yres)}.\n",
        "    min_res_bound: Minimum allowed resolution (inclusive).\n",
        "    max_res_bound: Maximum allowed resolution (inclusive).\n",
        "\n",
        "  Returns:\n",
        "    True if within bounds; otherwise False.\n",
        "  \"\"\"\n",
        "  if filename not in res_dict:\n",
        "    return False\n",
        "\n",
        "  xres, yres = res_dict[filename]\n",
        "\n",
        "  if (\n",
        "    xres < min_res_bound or xres > max_res_bound\n",
        "    or yres < min_res_bound or yres > max_res_bound\n",
        "  ):\n",
        "    return False\n",
        "\n",
        "  return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59skQ7yuH-j8"
      },
      "outputs": [],
      "source": [
        "def tiff_to_arr(filepath):\n",
        "  \"\"\"\n",
        "  Opens a .tiff file with Rasterio and returns its raw data as a numpy array,\n",
        "  plus the shape as a string.\n",
        "\n",
        "  Parameters:\n",
        "    filepath: Full path to the .tiff file.\n",
        "\n",
        "  Returns:\n",
        "    data_3D -> numpy array of shape (bands, rows, cols)\n",
        "    shape_str -> string representation of (rows, cols)\n",
        "  \"\"\"\n",
        "  with rasterio.open(filepath) as dataset:\n",
        "      data_array  = dataset.read()      # shape (bands, rows, cols)\n",
        "      shape_str   = str(dataset.shape)  # e.g. '(10, 10)'\n",
        "  return data_array, shape_str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUBd-pPL99tq"
      },
      "outputs": [],
      "source": [
        "def convert_3D_to_1D(data_3D):\n",
        "  \"\"\"\n",
        "  Reshapes a 3D array (bands, rows, cols) into (rows*cols, bands).\n",
        "\n",
        "  Parameters:\n",
        "    data_3D: NumPy array of shape (num_bands, num_rows, num_cols).\n",
        "\n",
        "  Returns:\n",
        "    NumPy array of shape (num_pixels, num_bands).\n",
        "  \"\"\"\n",
        "  # Flatten rows*cols, then transpose:\n",
        "  return data_3D.reshape(data_3D.shape[0], -1).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7WkIDcpVuFF"
      },
      "outputs": [],
      "source": [
        "def get_filenames(directory_path):\n",
        "  \"\"\"\n",
        "  Retrieves all files in a directory (no subfolders),\n",
        "  then sorts them by the integer prefix before '_' in the filename.\n",
        "\n",
        "  Parameters:\n",
        "    directory_path: Path to the directory containing .tiff files.\n",
        "\n",
        "  Returns:\n",
        "    A sorted np.array of filenames.\n",
        "  \"\"\"\n",
        "  files_in_dir = [\n",
        "      f for f in listdir(directory_path)\n",
        "      if isfile(join(directory_path, f)) and f.lower().endswith('.tiff')\n",
        "  ]\n",
        "  # Sort by integer portion (split on '_')\n",
        "  files_in_dir_sorted = sorted(files_in_dir, key=lambda x: int(x.split('_')[0]))\n",
        "  return np.array(files_in_dir_sorted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B1EJKnyaKDy"
      },
      "outputs": [],
      "source": [
        "def make_pandas_dataframe(\n",
        "  dir_path,\n",
        "  filename,\n",
        "  label=pd.NA,\n",
        "  uid=0\n",
        "):\n",
        "  \"\"\"\n",
        "  Converts one .tiff file (with known valid resolution) to a pandas DataFrame.\n",
        "  Automatically determines how many spectral bands are available.\n",
        "\n",
        "  Parameters:\n",
        "    dir_path: Directory where the .tiff file resides.\n",
        "    filename: The .tiff file name.\n",
        "    label: The label/class for all pixels in this image (default: NaN).\n",
        "    uid: A unique integer ID for the file (default: 0).\n",
        "\n",
        "  Returns:\n",
        "    A pandas DataFrame of shape (num_pixels, num_bands+4) with columns [frq0, frq1, ..., 'Label', 'Shape', 'File_UID_Num', 'File'].\n",
        "  \"\"\"\n",
        "  filepath_full = join(dir_path, filename)\n",
        "\n",
        "  # Read the 3D data and shape string from the .tiff\n",
        "  data_3D, shape_str = tiff_to_arr(filepath_full)\n",
        "\n",
        "  # Flatten from (bands, rows, cols) --> (rows*cols, bands)\n",
        "  data_2D = convert_3D_to_1D(data_3D)\n",
        "\n",
        "  # Dynamically name frequency columns based on the number of bands\n",
        "  num_bands = data_3D.shape[0]\n",
        "  freq_columns = [f\"frq{i}\" for i in range(num_bands)]\n",
        "\n",
        "  # Create DataFrame with band columns + metadata\n",
        "  df = pd.DataFrame(data_2D, columns=freq_columns)\n",
        "  df['Label'] = label\n",
        "  df['Shape'] = shape_str\n",
        "  df['File_UID_Num'] = uid\n",
        "  df['File'] = filename\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7h4P3G7CzyN"
      },
      "outputs": [],
      "source": [
        "def load_data_and_add_positions(csv_path):\n",
        "  \"\"\"\n",
        "  Loads the CSV that was saved from the main aggregator,\n",
        "  renames the first column to 'img_pxl_index',\n",
        "  and computes the pixel-level (row, col) location in each image.\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(csv_path)\n",
        "\n",
        "  if df.columns[0].lower().startswith('unnamed'):\n",
        "    df.rename(columns={df.columns[0]: 'img_pxl_index'}, inplace=True)\n",
        "  else:\n",
        "    # Otherwise, assume the first column is indeed the pixel index\n",
        "    df.rename(columns={df.columns[0]: 'img_pxl_index'}, inplace=True)\n",
        "\n",
        "  # Convert shape from string to actual tuple\n",
        "  df['Shape'] = df['Shape'].apply(literal_eval)\n",
        "\n",
        "  # Add pixel-level coordinate as a tuple\n",
        "  df['img_pos'] = df.apply(add_img_lvl_pixel_loc, axis=1)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgv3ThPcBv78"
      },
      "outputs": [],
      "source": [
        "def add_img_lvl_pixel_loc(row):\n",
        "  \"\"\"\n",
        "  Given a row with 'Shape' and 'img_pxl_index',\n",
        "  calculates the (row, col) within the image's 2D array.\n",
        "  'Shape' must be a tuple (rows, cols).\n",
        "  \"\"\"\n",
        "  shape_tuple = row['Shape']   # e.g. \"(100, 100)\" as a string or actual tuple\n",
        "  if isinstance(shape_tuple, str):\n",
        "      shape_tuple = literal_eval(shape_tuple)  # convert string to tuple\n",
        "\n",
        "  (num_rows, num_cols) = shape_tuple\n",
        "  pixel_index = row['img_pxl_index']\n",
        "\n",
        "  # row index is floor division by num_cols, col index is modulus\n",
        "  row_coord = pixel_index // num_cols\n",
        "  col_coord = pixel_index %  num_cols\n",
        "\n",
        "  return (row_coord, col_coord)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6wfczlwowtQ"
      },
      "source": [
        "### Main Function Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr6emIfCXlqC"
      },
      "outputs": [],
      "source": [
        "def get_all_data_single_dir(\n",
        "    tiff_directory,\n",
        "    label_csv_path,\n",
        "    res_dict,\n",
        "    min_res=4.0,\n",
        "    max_res=7.0,\n",
        "    label_col_1='Sample_num',\n",
        "    label_col_2='Class'\n",
        "):\n",
        "    \"\"\"\n",
        "    Reads all .tiff files in `tiff_directory` and their corresponding labels from `label_csv_path`.\n",
        "    Checks resolution using `res_dict`. Creates a large DataFrame of all valid .tiff files.\n",
        "    Automatically extracts the number of spectral bands from each file.\n",
        "\n",
        "    Parameters:\n",
        "      tiff_directory: Path to the directory containing all .tiff files.\n",
        "      label_csv_path: Path to the CSV that contains (sample_num, label) info.\n",
        "      res_dict: A dictionary of {filename: (x_res, y_res)} loaded from the resolution CSV.\n",
        "      min_res: Minimum allowed resolution. (default: 4.0)\n",
        "      max_res: Maximum allowed resolution. (default: 7.0)\n",
        "      label_col_1: Column name in label CSV that is the sample_num. (default: 'Sample_num')\n",
        "      label_col_2: Column name in label CSV that is the class/label. (default: 'Class')\n",
        "\n",
        "    Returns:\n",
        "      (df, df_files)\n",
        "      df -> A pandas DataFrame of all pixel data across valid .tiff files.\n",
        "      df_files -> A pandas DataFrame with columns ['Label','UID','Filename'] for each included .tiff file.\n",
        "    \"\"\"\n",
        "    print(\"=== Starting Data Aggregation ===\")\n",
        "\n",
        "    # Load label CSV\n",
        "    labels = get_labels(\n",
        "        file_path=label_csv_path,\n",
        "        col1=label_col_1,\n",
        "        col2=label_col_2,\n",
        "        name_col_id='Sample_num',\n",
        "        name_col_label='Label'\n",
        "    )\n",
        "\n",
        "    # Gather and sort filenames in directory\n",
        "    filenames = get_filenames(tiff_directory)\n",
        "\n",
        "    # Trim filenames to only those that have a matching label\n",
        "    print(\"Trimming filenames to match labels...\")\n",
        "    trimmed_filenames = trim_data_files(filenames, labels, 'Sample_num')\n",
        "    print(f\"Number of files with matching labels: {len(trimmed_filenames)} / {len(filenames)}\")\n",
        "\n",
        "    df_list     = []\n",
        "    included    = []\n",
        "    uid_counter = 1\n",
        "\n",
        "    # Iterate over each trimmed filename\n",
        "    for fname in trimmed_filenames:\n",
        "        sample_num   = int(fname.split('_')[0])\n",
        "        label_value  = labels.loc[labels['Sample_num'] == sample_num, 'Label'].values[0]\n",
        "\n",
        "        # Check resolution using CSV-based res_dict\n",
        "        if check_res(fname, res_dict, min_res_bound=min_res, max_res_bound=max_res):\n",
        "\n",
        "            # Convert this TIFF to a DataFrame\n",
        "            df_temp = make_pandas_dataframe(\n",
        "                dir_path=tiff_directory,\n",
        "                filename=fname,\n",
        "                label=label_value,\n",
        "                uid=uid_counter\n",
        "            )\n",
        "            df_list.append(df_temp)\n",
        "            included.append((label_value, uid_counter, fname))\n",
        "            uid_counter += 1\n",
        "        else:\n",
        "            pass  # resolution check failed\n",
        "\n",
        "    # Concatenate all valid DataFrames\n",
        "    if not df_list:\n",
        "        raise ValueError(\"No valid .tiff files passed the resolution check.\")\n",
        "\n",
        "    df_all = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "    # Create a file-level DataFrame\n",
        "    df_files = pd.DataFrame(included, columns=['Label','UID','Filename'])\n",
        "\n",
        "    print(\"=== Data Aggregation Complete ===\")\n",
        "    return df_all, df_files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nde8-P7vVpQI"
      },
      "source": [
        "## Main Run\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Ljj-9E9sAi"
      },
      "outputs": [],
      "source": [
        "#############################################\n",
        "#               LOAD RESOLUTIONS\n",
        "#############################################\n",
        "# Loading the CSV of x_res and y_res so that we can check\n",
        "# resolutions without relying on Rasterio for this information. (bit quicker given we have the metadata)\n",
        "\n",
        "# The CSV (res_csv_path) must have these columns: file_name, x_res, y_res\n",
        "\n",
        "df_resolutions = pd.read_csv(res_csv_path)\n",
        "# Create a dictionary: { \"some_file.tiff\": (x_res, y_res), ... }\n",
        "\n",
        "res_dict = {}\n",
        "for idx, row in df_resolutions.iterrows():\n",
        "  # ASSUMPTION: file_name is EXACTLY the .tiff file's name (As it should be lol...)\n",
        "  filename = row['file_name']\n",
        "  xres     = float(row['x_res'])\n",
        "  yres     = float(row['y_res'])\n",
        "  res_dict[filename] = (xres, yres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR2kbg4DArNF"
      },
      "outputs": [],
      "source": [
        "# Run the main data retrieval using our single directory approach\n",
        "# CAUTION: So Slow... this took 22 to 41 minutes to run. Depends on Google, idk?\n",
        "df, valid_files = get_all_data_single_dir(\n",
        "    tiff_directory = tiff_dir,\n",
        "    label_csv_path = labels_csv,\n",
        "    res_dict       = res_dict,     # loaded from ANG_L2A_v2_sample_subset_resolutions.csv\n",
        "    min_res        = 4.0,          # Defined resolution boundaries\n",
        "    max_res        = 7.0,\n",
        "    label_col_1    = 'Sample_num',\n",
        "    label_col_2    = 'Class'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otRgGckTB6Jt"
      },
      "outputs": [],
      "source": [
        "# Adding Pixel-Level Locations\n",
        "df = load_data_and_add_positions(path_to_save_sample_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeJBZxAEdNhE"
      },
      "source": [
        "### View Data Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNW5vKWMXPNZ"
      },
      "outputs": [],
      "source": [
        "# Lets check it out; Pandas Data Frame\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEzMfg5Kx4Be"
      },
      "outputs": [],
      "source": [
        "# Check out Files and UID; Numpy Array\n",
        "valid_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyh7QwOVdVoy"
      },
      "source": [
        "### Save To CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IxqshZ_Jaay"
      },
      "outputs": [],
      "source": [
        "df.to_csv(path_to_save_sample_csv, index=False)\n",
        "valid_files.to_csv(path_to_save_uid_csv, index=False)\n",
        "\n",
        "print(f\"Saved pixel-level data to: {path_to_save_sample_csv}\")\n",
        "print(f\"Saved file-UID map to:     {path_to_save_uid_csv}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2urNHkRy-5A1",
        "zv-jWjKh-jC3",
        "Bg6txo5K-nxm",
        "L5aJk6Q1-9Ep",
        "DLmTehCoOnsp",
        "c7n8gu-gWFU0",
        "QzSS_fnpo3UK",
        "w6wfczlwowtQ",
        "sm6W7bFGIHID",
        "oWOUfFaio72j",
        "1Amm02oFpA-o",
        "nde8-P7vVpQI",
        "SeJBZxAEdNhE",
        "Nyh7QwOVdVoy",
        "aDlSORaGYGVJ",
        "WDy2oLJgo_kY",
        "irYrok5wpBe9",
        "6R-BDHTapD7S",
        "PiXkkLvfDHOr"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
